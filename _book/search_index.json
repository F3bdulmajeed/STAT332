[["properties-inferences-in-regression.html", "2 Properties inferences in Regression 2.1 Recap 2.2 Exercises 2.3 Coursework", " 2 Properties inferences in Regression 2.1 Recap Previously we discuss the least squared approach to estimate the slop and the bias parameter in the simple linear model. An important question arises here is to test how significant is our estimation and in order to assess that let us assume the error term is normally distributed with zero mean and constant variance \\(\\sigma^2\\). We want to test \\(H_0 : \\beta_j = \\hat{\\beta}~~~ \\text{vs.}~ ~~H_1 : \\beta_{j}= \\hat{\\beta}\\) at level \\(\\alpha\\) where \\(\\beta\\) is some constant and \\(j=0,1\\). The decision rule is to reject \\(H_0\\) if: \\[|T|=\\lvert~\\frac{\\beta_j-{\\hat\\beta}}{SE(\\hat\\beta_j)}\\lvert~&gt; t_{n-2,\\alpha/2}\\] Where \\(SE()\\) is the standard error of the parameter. Recall that from the lecture note: \\[\\begin{align} &amp;Var(\\beta_1)=\\frac{\\sigma^2}{(n-1)S_{X&#39;X&#39;}} = \\frac{\\sigma^2}{\\sum (x_i-\\bar{x})2}\\\\ &amp;Var(\\beta_0)= \\sigma^2 (\\frac{1}{n}+\\frac{\\bar{X}^2}{\\sum (x_i-\\bar{x})2}) \\end{align}\\] 2.2 Exercises Exercise 2.1 Go back to Exercise 1.3 and test the hypothesis that the yield is proportional to the amount of catalyst cubed. Solution 2.1: Now \\(Var(\\beta)=\\frac{\\sigma^2}{(n-1)S_{X&#39;X&#39;}}\\) \\[(n-1)S_{X&#39;X&#39;}=\\sum_{i=1}^{n}x&#39;^2_i-\\frac{(\\sum_{i=1}^{n}x&#39;_i)^2}{n}=0.33\\] While \\(\\sigma^2\\) can be estimated by using the unbiased estimator \\(s^2\\), \\[s^2=\\frac{1}{2}\\sum_{i=1}^{n}(y&#39;_i-\\hat{y&#39;_i})^2=0.0018\\] Hence \\(SE(\\beta)=\\sqrt{Var(\\hat\\beta)}= 0.0739\\). Now to test \\(H_0: \\beta=3\\) against \\(H_q: \\beta\\neq3\\) Under \\(H_0\\), the T-test is \\(-0.0932\\) So the p-value is \\(P(|t4| &gt; 0.0932) = 2P(t4 &lt; 0.0932) = 0.9302\\). There is therefore no evidence to reject \\(H_0\\) i.e. no evidence against a cubic relationship. Exercise 2.2: The results of a class of 10 students on midterm marks \\(X\\) and on the final marks \\(Y\\) are as follows: X 77 54 71 72 81 94 96 99 83 67 Y 82 38 78 34 37 85 99 99 79 67 Calculate the regression line by hand. interpret the result. Construct \\(95\\%\\) confidence intervals for the bais and the slope coefficients and explain the results.. Use the lm() function in R to calculate regression line. Use the confint() in R to construct \\(95\\%\\) confidence intervals for the model coefficients. plot the regression line using the function plot(). 2.3 Coursework "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
